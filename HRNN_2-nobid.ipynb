{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第二版不同之处在于使用全连接层进行特征融合\n",
    "#Step1.导入包并选定设备\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "import time\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#说明：该版本仅在59.1的版本基础上加了一个双向"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step2.模型参数设置\n",
    "\n",
    "sequence_length = 300  #序列长度，最大帧为300，但这里还需要更改\n",
    "input_size = 75       #输入数据特征大小 3（x,y,z）*25（关节数量）\n",
    "hidden_size = 128     #隐藏层数据特征大小,即每个时间步对应的ht的维数\n",
    "num_layers = 2        #隐藏层层数\n",
    "num_classes = 60      #结果类数\n",
    "batch_size = 1000     #一个batch大小\n",
    "num_epochs = 50       #epoch数目\n",
    "learning_rate = 0.001  #学习率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 新增代码\n",
    "# 用于读取数据集\n",
    "import pickle\n",
    "import numpy as np\n",
    "class Feeder(torch.utils.data.Dataset):\n",
    "    \"\"\" \n",
    "    参数：\n",
    "    data_path:.npy形式的数据的路径，数据的格式需要是(N,C,T,V,M)\n",
    "        N：样本数目，C：有几个相机，T：帧数，V：有几个关节点，M：动作次数\n",
    "    label_path：标签的路径\n",
    "    random_choose：如果为真，则随机的选择输入序列中的一部分\n",
    "    random_shift:如果为真，则在序列的开始和结束时随机的填充0\n",
    "    window_size:输出序列的宽度\n",
    "    normalization:如果为真，则对序列进行标准化\n",
    "    debug:如果为真，则仅使用前100个样本\n",
    "    mmap：如果为真，则使用虚拟内存映射（因为数据集太大了，故需要虚拟内存映射）\n",
    "    \"\"\"\n",
    "\n",
    "    '''\n",
    "    使用了标准化的版本\n",
    "    def __init__(self,\n",
    "                 data_path,\n",
    "                 label_path,\n",
    "                 random_choose=False,\n",
    "                 random_move=False,\n",
    "                 window_size=-1,\n",
    "                 debug=False,\n",
    "                 mmap=True):\n",
    "        self.debug = debug\n",
    "        self.data_path = data_path\n",
    "        self.label_path = label_path\n",
    "        self.random_choose = random_choose\n",
    "        self.random_move = random_move\n",
    "        self.window_size = window_size\n",
    "        self.load_data(mmap)\n",
    "    '''\n",
    "    \n",
    "    def __init__(self,\n",
    "                 data_path,\n",
    "                 label_path,\n",
    "                 window_size=-1,\n",
    "                 debug=False,\n",
    "                 mmap=True):\n",
    "        self.debug = debug\n",
    "        self.data_path = data_path\n",
    "        self.label_path = label_path\n",
    "        self.window_size = window_size\n",
    "        self.load_data(mmap)\n",
    "        \n",
    "    def load_data(self, mmap):\n",
    "        # data: N C V T M\n",
    "\n",
    "        # 加载标签\n",
    "        with open(self.label_path, 'rb') as f:\n",
    "            self.sample_name, self.label = pickle.load(f)\n",
    "\n",
    "        # load data\n",
    "        if mmap:\n",
    "            # 如果使用了虚拟内存映射，则使用虚拟内存映射模式加载数据\n",
    "            self.data = np.load(self.data_path, mmap_mode='r')\n",
    "        else:\n",
    "            self.data = np.load(self.data_path)\n",
    "            \n",
    "        # 如果是debug模式，则不载入全部数据,注：原来是100，为了方便观察这里改成的2\n",
    "        if self.debug:\n",
    "            self.label = self.label[0:10]\n",
    "            self.data = self.data[0:10]\n",
    "            self.sample_name = self.sample_name[0:10]\n",
    "\n",
    "        self.N, self.C, self.T, self.V, self.M = self.data.shape\n",
    "\n",
    "    # 获取数据集大小\n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "\n",
    "    # 用于获取某一个数据的函数\n",
    "    def __getitem__(self, index):\n",
    "        data_numpy = np.array(self.data[index])\n",
    "        label = self.label[index]\n",
    "        \n",
    "        \"\"\"\n",
    "        预处理过程，后续可以在此基础上补充\n",
    "        注：预处理是在__getitem__中进行的\n",
    "        if self.random_choose:\n",
    "            data_numpy = tools.random_choose(data_numpy, self.window_size)\n",
    "        elif self.window_size > 0:\n",
    "            data_numpy = tools.auto_pading(data_numpy, self.window_size)\n",
    "        if self.random_move:\n",
    "            data_numpy = tools.random_move(data_numpy)\n",
    "        \"\"\"\n",
    "        return data_numpy, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 新增代码\n",
    "# 用于读取数据\n",
    "'''\n",
    "self,\n",
    "data_path,\n",
    "label_path,\n",
    "window_size=-1,\n",
    "debug=False,\n",
    "mmap=True)\n",
    "'''\n",
    "train_set = Feeder(data_path='./cooked_data/xsub/train_data.npy',\n",
    "                  label_path='./cooked_data/xsub/train_label.pkl',\n",
    "                  )\n",
    "\n",
    "test_set = Feeder(data_path='./cooked_data/xsub/val_data.npy',\n",
    "                  label_path='./cooked_data/xsub/val_label.pkl',\n",
    "                  )\n",
    "\n",
    "# 添加了一个debug_set用于观察数据\n",
    "debug_set = Feeder(data_path='./cooked_data/xsub/train_data.npy',\n",
    "                  label_path='./cooked_data/xsub/train_label.pkl',\n",
    "                   debug=True,\n",
    "                  )\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set,\n",
    "                                      batch_size = batch_size,\n",
    "                                      shuffle = True,\n",
    "                                      num_workers = 4,\n",
    "                                        drop_last=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_set,\n",
    "                                      batch_size = batch_size,\n",
    "                                      num_workers = 4,\n",
    "                                         drop_last=True)\n",
    "\n",
    "\n",
    "debug_loader = torch.utils.data.DataLoader(debug_set,\n",
    "                                           batch_size = 10,\n",
    "                                      num_workers = 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n"
     ]
    }
   ],
   "source": [
    "# 第0维代表是第几个样本\n",
    "# 第一维存的是关节的x,y,z坐标\n",
    "# 第二维用于标识是哪一帧\n",
    "# 第三维用于标识是哪个关节\n",
    "# 第四维用于表示是哪个身体\n",
    "# 1*3*300*25*2->1*3*300*25*1最后只取了一个身体方便计算\n",
    "# batch_x = batch_x.view(-1,sequence_length,input_size)\n",
    "\n",
    "'''\n",
    "for batch_x,batch_y in debug_loader:\n",
    "    for i in range(5):\n",
    "        print(batch_x.size(i))\n",
    "        \n",
    "    print('\\n')\n",
    "    batch_x = batch_x[:,:,:,:,0].view(-1,300,75)\n",
    "    for i in range(3):\n",
    "        print(batch_x.size(i))\n",
    "    print(batch_y)\n",
    "'''\n",
    "for batch_x,batch_y in debug_loader:\n",
    "    print(batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step4.模型定义\n",
    "# 数据类型\n",
    "# 数据的第0维是序号即代表是哪一个样本\n",
    "# 第一维存的是关节的x,y,z坐标\n",
    "# 第二维用于标识是哪一帧\n",
    "# 第三维用于标识是哪个关节\n",
    "# 第四维用于表示是哪个身体\n",
    "class HRNN(nn.Module):\n",
    "    # 实现三层架构，即首先经过两层普通BRNN并经过全连接层融合，最后经过一层LSTM的BRNN，然后用FC表示\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(HRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        #如果要使用反向的传递，则需令bidirectional=True\n",
    "        # batch_first代表传入数据为（batch,seq,feature)的顺序 否则Pytroch所有RNN网络默认输入结构为(seq,batch,feature)\n",
    "        # batch_first = true代表输入X为 batch_size,seq_len,input_size\n",
    "        # 为了测试循环的提升，将True改成了False\n",
    "        self.rnn = nn.RNN(int(input_size/5), int(hidden_size/2), num_layers, batch_first=True, bidirectional=False)\n",
    "        self.rnn2 = nn.RNN(hidden_size, hidden_size*2, num_layers, batch_first=True, bidirectional=False)\n",
    "        self.lstm = nn.LSTM(int(hidden_size/4*2*2), hidden_size*2, num_layers, batch_first=True, bidirectional=False)\n",
    "        \n",
    "        \n",
    "        #如果使用了反向传递，则需要将hidden_size*2!\n",
    "        self.fc = nn.Linear(hidden_size*2*sequence_length, num_classes)\n",
    "        self.fs1 = nn.Linear(hidden_size,hidden_size)\n",
    "        self.fs2 = nn.Linear(hidden_size*4,hidden_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # 输入：\n",
    "        # X为batch_size*seq_len*input_size(batch_first=true时)\n",
    "        \n",
    "        # 输出：\n",
    "        # 输出为out,(hn,cn)\n",
    "        # out(seq_len, batch_size, num_directions*hidden_size) 即为[h1,h2,...,hseq_len]\n",
    "        # 即out = torch.Size([1000, 28, 128])\n",
    "        # out: tensor of shape (batch_size, seq_length, hidden_size*2)\n",
    "        '''\n",
    "        in2_p1 = torch.zeros(400,28,128)\n",
    "        in2_p2 = torch.zeros(400,28,128)\n",
    "        in2_p3 = torch.zeros(400,28,128)\n",
    "        in2_p4 = torch.zeros(400,28,128)\n",
    "        \n",
    "        in3_p1 = torch.zeros(800,28,128)\n",
    "        in3_p2 = torch.zeros(800,28,128)\n",
    "        \n",
    "        in4_p1 = torch.zeros(1600,28,128)\n",
    "        '''\n",
    "        # layer1:即分成五个部分利用rnn进行分别建模 75/5\n",
    "        # step1:将五个部分分别经过rnn层\n",
    "        (x_p1,x_p2,x_p3,x_p4,x_p5) = torch.chunk(x, 5, dim = 2)\n",
    "        out1_p1,_ = self.rnn(x_p1)\n",
    "        out1_p2,_ = self.rnn(x_p2)\n",
    "        out1_p3,_ = self.rnn(x_p3)\n",
    "        out1_p4,_ = self.rnn(x_p4)\n",
    "        out1_p5,_ = self.rnn(x_p5)\n",
    "        # 经过第一个RNN得到的是五个子部分的表示\n",
    "        \n",
    "        \n",
    "        # step2:利用全连接层进行特征融合\n",
    "        # 先进行特征拼接\n",
    "        temp2_p1 = torch.cat((out1_p1,out1_p2),2) #(,,128/4*2*2),第一个2为双向乘的，第二个2为两个并在一起乘的\n",
    "        temp2_p2 = torch.cat((out1_p1,out1_p3),2)\n",
    "        temp2_p3 = torch.cat((out1_p1,out1_p4),2)\n",
    "        temp2_p4 = torch.cat((out1_p1,out1_p5),2)\n",
    "        \n",
    "        # 再进行特征融合\n",
    "        seqs = temp2_p1.size(1)\n",
    "        in2_p1 = []\n",
    "        for seq in range(seqs):\n",
    "            temp = torch.squeeze(temp2_p1[:,seq,:],dim=1) #删除这个维度\n",
    "            in2_p1_i = F.relu(self.fs1(temp))\n",
    "            in2_p1.append(in2_p1_i)\n",
    "        in2_p1 = torch.stack(in2_p1,dim = 1)\n",
    "        in2_p2 = []\n",
    "        for seq in range(seqs):\n",
    "            temp = torch.squeeze(temp2_p2[:,seq,:],dim=1) #删除这个维度\n",
    "            in2_p2_i = F.relu(self.fs1(temp))\n",
    "            in2_p2.append(in2_p2_i)\n",
    "        in2_p2 = torch.stack(in2_p2,dim = 1)\n",
    "        in2_p3 = []\n",
    "        for seq in range(seqs):\n",
    "            temp = torch.squeeze(temp2_p3[:,seq,:],dim=1) #删除这个维度\n",
    "            in2_p3_i = F.relu(self.fs1(temp))\n",
    "            in2_p3.append(in2_p3_i)\n",
    "        in2_p3 = torch.stack(in2_p3,dim = 1)\n",
    "        in2_p4 = []\n",
    "        for seq in range(seqs):\n",
    "            temp = torch.squeeze(temp2_p4[:,seq,:],dim=1) #删除这个维度\n",
    "            in2_p4_i = F.relu(self.fs1(temp))\n",
    "            in2_p4.append(in2_p4_i)\n",
    "        in2_p4 = torch.stack(in2_p4,dim = 1)\n",
    "        \n",
    "        \n",
    "        # layer2:用4个部分进行输入，得到结果经过融合层变成两部分\n",
    "        # step1:四个部分分别经过第二个rnn层\n",
    "        out2_p1,_ = self.rnn2(in2_p1)\n",
    "        out2_p2,_ = self.rnn2(in2_p2)\n",
    "        out2_p3,_ = self.rnn2(in2_p3)\n",
    "        out2_p4,_ = self.rnn2(in2_p4)\n",
    "        \n",
    "        # step2:利用全连接层进行特征融合\n",
    "        temp3_p1 = torch.cat((out2_p1,out2_p2),2)\n",
    "        temp3_p2 = torch.cat((out2_p3,out2_p4),2)\n",
    "        seqs = temp3_p1.size(1)\n",
    "        in3_p1 = []\n",
    "        for seq in range(seqs):\n",
    "            temp = torch.squeeze(temp3_p1[:,seq,:],dim=1) #删除这个维度\n",
    "            in3_p1_i = F.relu(self.fs2(temp))\n",
    "            in3_p1.append(in3_p1_i)\n",
    "        in3_p1 = torch.stack(in3_p1,dim = 1)\n",
    "        \n",
    "        in3_p2 = []\n",
    "        for seq in range(seqs):\n",
    "            temp = torch.squeeze(temp3_p2[:,seq,:],dim=1) #删除这个维度\n",
    "            in3_p2_i = F.relu(self.fs2(temp))\n",
    "            in3_p2.append(in3_p2_i)\n",
    "        in3_p2 = torch.stack(in3_p2,dim = 1)\n",
    "        \n",
    "        # layer3:将两个部分的结果再经过rnn层最终得到一个部分的结果\n",
    "        # step1:将两个部分分别经过rnn\n",
    "        out3_p1,_ = self.rnn2(in3_p1)\n",
    "        out3_p2,_ = self.rnn2(in3_p2)\n",
    "        \n",
    "        # step2.利用全连接层进行特征融合\n",
    "        temp4_p1 = torch.cat((out3_p1,out3_p2),2)\n",
    "        in4_p1 = []\n",
    "        for seq in range(seqs):\n",
    "            temp = torch.squeeze(temp4_p1[:,seq,:],dim=1) #删除这个维度\n",
    "            in4_p1_i = F.relu(self.fs2(temp))\n",
    "            in4_p1.append(in4_p1_i)\n",
    "        in4_p1 = torch.stack(in4_p1,1)\n",
    "        \n",
    "        # layer3:整体作为输入经过lstm层得到输出\n",
    "        out4,_ = self.lstm(in4_p1)\n",
    "        #print(out4.shape) torch.Size([1000, 300, 128])\n",
    "        # 代表仅取最后一个时间步的隐状态表示作为全连接层的输入(这显然是不合理的，因为有很多都没有到最后一帧)\n",
    "        #out = self.fc(out4[:, -1, :])\n",
    "        # 尝试一：将向量展平（但这样会存在很多0）\n",
    "        out = self.fc(out4.reshape(out4.size(0),hidden_size*2*sequence_length))\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# 该模型仅用于测试\\nclass TestFC(nn.Module):\\n    def __init__(self, input_size, hidden_size, num_layers, num_classes):\\n        super(TestFC, self).__init__()\\n        self.hidden_size = hidden_size\\n        self.num_layers = num_layers\\n        self.input_size = input_size\\n        self.num_classes = num_classes\\n        \\n        \\n        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\\n        self.fc = nn.Linear(hidden_size*2*sequence_length,num_classes)\\n        \\n        \\n    def forward(self, x):\\n        out1,_ = self.rnn(x)\\n        #print(out1.shape)\\n        #torch.Size([1000, 300, 128])\\n        out = self.fc(out1.reshape(out1.size(0),hidden_size*2*sequence_length))\\n        return out\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# 该模型仅用于测试\n",
    "class TestFC(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(TestFC, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.input_size = input_size\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        \n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_size*2*sequence_length,num_classes)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        out1,_ = self.rnn(x)\n",
    "        #print(out1.shape)\n",
    "        #torch.Size([1000, 300, 128])\n",
    "        out = self.fc(out1.reshape(out1.size(0),hidden_size*2*sequence_length))\n",
    "        return out\n",
    "'''\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step5.定义辅助函数用于模型评估\n",
    "def eval(model,criterion,dataloader):\n",
    "    loss = 0\n",
    "    accuracy = 0\n",
    "    for batch_x, batch_y in dataloader:\n",
    "        batch_x = batch_x[:,:,:,:,0].view(-1,sequence_length,input_size)\n",
    "        # batch_y = F.one_hot(batch_y,num_class)\n",
    "        batch_x, batch_y = batch_x.to(device),batch_y.to(device)\n",
    "        \n",
    "        logits = model(batch_x)\n",
    "        error = criterion(logits,batch_y)\n",
    "        loss += error.item()\n",
    "        \n",
    "        probs,pred_y = logits.data.max(dim=1)\n",
    "        accuracy += (pred_y==batch_y.data).sum().double()/batch_y.size(0)\n",
    "        \n",
    "    loss /= len(dataloader)\n",
    "    accuracy = accuracy*100.0/len(dataloader)\n",
    "    return loss,accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step6.模型使用以及损失函数、优化函数使用\n",
    "model = HRNN(input_size, hidden_size, num_layers, num_classes).to(device)\n",
    "model.train()\n",
    "# 使用交叉熵损失函数作为目标函数\n",
    "# 使用Adam作为优化函数\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/50,270 seconds],train error:4.1e+00, train acc:1.68\t test error: 4.1e+00,test acc: 1.68\n",
      "[2/50,269 seconds],train error:3.5e+00, train acc:11.97\t test error: 3.6e+00,test acc: 11.82\n",
      "[3/50,269 seconds],train error:2.9e+00, train acc:21.15\t test error: 3.0e+00,test acc: 20.23\n",
      "[4/50,269 seconds],train error:2.5e+00, train acc:31.07\t test error: 2.6e+00,test acc: 28.82\n",
      "[5/50,269 seconds],train error:2.1e+00, train acc:40.65\t test error: 2.3e+00,test acc: 36.94\n",
      "[6/50,269 seconds],train error:1.8e+00, train acc:46.65\t test error: 2.1e+00,test acc: 40.58\n",
      "[7/50,269 seconds],train error:1.6e+00, train acc:53.39\t test error: 2.0e+00,test acc: 45.67\n",
      "[8/50,269 seconds],train error:1.4e+00, train acc:57.14\t test error: 1.9e+00,test acc: 47.45\n",
      "[9/50,269 seconds],train error:1.3e+00, train acc:62.53\t test error: 1.8e+00,test acc: 50.21\n",
      "[10/50,269 seconds],train error:1.1e+00, train acc:66.33\t test error: 1.8e+00,test acc: 51.44\n",
      "[11/50,269 seconds],train error:1.0e+00, train acc:69.20\t test error: 1.8e+00,test acc: 51.52\n",
      "[12/50,269 seconds],train error:8.5e-01, train acc:74.29\t test error: 1.8e+00,test acc: 52.39\n",
      "[13/50,270 seconds],train error:7.2e-01, train acc:77.77\t test error: 1.9e+00,test acc: 53.31\n",
      "[14/50,280 seconds],train error:6.3e-01, train acc:80.35\t test error: 2.0e+00,test acc: 52.99\n",
      "[15/50,269 seconds],train error:5.5e-01, train acc:82.81\t test error: 2.1e+00,test acc: 52.09\n",
      "[16/50,269 seconds],train error:4.4e-01, train acc:86.27\t test error: 2.2e+00,test acc: 53.29\n",
      "[17/50,270 seconds],train error:3.1e-01, train acc:91.01\t test error: 2.2e+00,test acc: 53.46\n",
      "[18/50,269 seconds],train error:2.5e-01, train acc:92.46\t test error: 2.4e+00,test acc: 53.86\n",
      "[19/50,269 seconds],train error:2.2e-01, train acc:93.22\t test error: 2.6e+00,test acc: 53.41\n",
      "[20/50,269 seconds],train error:1.6e-01, train acc:95.52\t test error: 2.7e+00,test acc: 53.47\n",
      "[21/50,269 seconds],train error:1.0e-01, train acc:97.51\t test error: 2.8e+00,test acc: 53.79\n",
      "[22/50,269 seconds],train error:8.5e-02, train acc:98.00\t test error: 2.8e+00,test acc: 54.02\n",
      "[23/50,270 seconds],train error:5.6e-02, train acc:98.86\t test error: 3.0e+00,test acc: 54.02\n",
      "[24/50,270 seconds],train error:4.9e-02, train acc:98.97\t test error: 3.1e+00,test acc: 54.19\n",
      "[25/50,269 seconds],train error:5.0e-02, train acc:98.91\t test error: 3.1e+00,test acc: 53.95\n",
      "[26/50,270 seconds],train error:2.7e-02, train acc:99.62\t test error: 3.3e+00,test acc: 54.63\n",
      "[27/50,270 seconds],train error:1.3e-02, train acc:99.91\t test error: 3.3e+00,test acc: 54.81\n",
      "[28/50,270 seconds],train error:1.1e-02, train acc:99.89\t test error: 3.4e+00,test acc: 54.67\n",
      "[29/50,270 seconds],train error:4.8e-03, train acc:100.00\t test error: 3.5e+00,test acc: 55.27\n",
      "[30/50,270 seconds],train error:3.3e-03, train acc:100.00\t test error: 3.4e+00,test acc: 55.79\n",
      "[31/50,269 seconds],train error:2.6e-03, train acc:100.00\t test error: 3.5e+00,test acc: 55.65\n",
      "[32/50,270 seconds],train error:2.0e-03, train acc:100.00\t test error: 3.6e+00,test acc: 55.64\n",
      "[33/50,270 seconds],train error:1.6e-03, train acc:100.00\t test error: 3.6e+00,test acc: 55.81\n",
      "[34/50,269 seconds],train error:1.5e-03, train acc:100.00\t test error: 3.6e+00,test acc: 55.61\n",
      "[35/50,269 seconds],train error:1.7e-03, train acc:100.00\t test error: 3.6e+00,test acc: 55.70\n",
      "[36/50,269 seconds],train error:1.6e-03, train acc:100.00\t test error: 3.7e+00,test acc: 55.70\n",
      "[37/50,269 seconds],train error:1.4e-03, train acc:100.00\t test error: 3.7e+00,test acc: 55.44\n",
      "[38/50,269 seconds],train error:1.5e-03, train acc:100.00\t test error: 3.7e+00,test acc: 55.71\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step7.模型训练\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    since = time.time()\n",
    "    for batch_x,batch_y in train_loader:\n",
    "        # 暂时只取了第一个身体\n",
    "        batch_x = batch_x[:,:,:,:,0].view(-1,sequence_length,input_size)\n",
    "        # batch_y = F.one_hot(batch_y,num_classes)\n",
    "        # print(batch_x.size(0))\n",
    "        batch_x,batch_y = batch_x.to(device),batch_y.to(device)\n",
    "        # print(batch_y.shape)\n",
    "        # print(batch_x.shape)\n",
    "        optimizer.zero_grad()\n",
    "        logit = model(batch_x)\n",
    "        # print(logit.shape)\n",
    "        # print(batch_y.shape)\n",
    "        E = criterion(logit,batch_y)\n",
    "        E.backward()\n",
    "        optimizer.step()\n",
    "    now = time.time()\n",
    "    model.eval()\n",
    "    tr_loss, tr_acc = eval(model,criterion,train_loader)\n",
    "    te_loss, te_acc = eval(model,criterion,test_loader)\n",
    "    print('[%d/%d,%.0f seconds],train error:%.1e, train acc:%.2f\\t test error: %.1e,test acc: %.2f'%(epoch+1,num_epochs,now-since,tr_loss,tr_acc,te_loss,te_acc))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step8.用于测试\n",
    "for batch_x,batch_y in debug_loader:\n",
    "    batch_x = batch_x[:,:,:,:,0].view(-1,sequence_length,input_size)\n",
    "    zero_bone = [0.0000 for _ in range(75)]\n",
    "    #print(batch_x.shape)\n",
    "    #print(batch_x)\n",
    "    # print(zero_bone)\n",
    "    print(batch_x[0,:,:])\n",
    "    print((batch_x[0,:,:] == zero_bone).nonzero(as_tuple = True)[0])\n",
    "    \n",
    "    batch_x,batch_y = batch_x.to(device),batch_y.to(device)\n",
    "    logit = model(batch_x)\n",
    "    print(logit)\n",
    "    '''\n",
    "    pred_y = logit.data.max(dim=1)\n",
    "    print(pred_y)\n",
    "    '''\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#Step6.模型训练、测试与保存\n",
    "total_step = len(train_loader)\n",
    "print(total_step)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "        labels = labels.to(device)\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "\n",
    "# Test the model\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total)) \n",
    "\n",
    "# Save the model checkpoint\n",
    "torch.save(model.state_dict(), 'model.ckpt')\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_capability(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nvidia' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-bc6386d60349>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnvidia\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0msmi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'nvidia' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
